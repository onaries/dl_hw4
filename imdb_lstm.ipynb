{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras.python.keras.preprocessing import sequence\n",
    "from tensorflow.contrib.keras.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.contrib.keras.python.keras.models import Sequential, Model\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dense, Embedding, LSTM, Input, merge, BatchNormalization, Dropout\n",
    "from tensorflow.contrib.keras.python.keras.datasets import imdb\n",
    "from tensorflow.contrib.keras.python.keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variour variable\n",
    "max_features = 20000\n",
    "maxlen = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./aclImdb/train/pos/'\n",
    "x_train.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_train.extend([1 for _ in range(12500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./aclImdb/train/neg/'\n",
    "x_train.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_train.extend([0 for _ in range(12500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "['This movie makes me want to fall in love all over again!I am naming my next daughter \"Adelaide\". Just so that someone who sings like Ol Blue eyes can swoon her one day, and feel the butterflies I felt hearing it sung, and it wasn\\'t even to me! I give it a 9/10']\n"
     ]
    }
   ],
   "source": [
    "print('x:')\n",
    "print(x_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print('y:')\n",
    "print(y_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./aclImdb/test/pos/'\n",
    "x_test.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_test.extend(1 for _ in range(12500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./aclImdb/test/neg/'\n",
    "x_test.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_test.extend(0 for _ in range(12500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "['Boogie Nights is perhaps one of the greatest examples any would-be filmmaker should take a long hard look at. Sure, you could spend loads of quality time reviewing the clasics from Hitchcock to Scorsese; but lets follow suit for the modern generation and study half-heartedly.<br /><br />Where to begin, I suppose one could look at the film as simply a story, perhaps even docudrama which focuses on the late 1970\\'s porn industry-and what an industry it was! The other half could focus on the incredible detail one brillant filmmaker can achieve simply by using polyester and *ahem* rubber. But honestly, Boogie Nights brings back the pure, no-bul!shi$, in your face kind of cinema I haven\\'t experienced since the film greats of the 1970\\'s...ironic...or stroke of genius. The story is full of richly detailed characters, all of which you either can relate too, love, or hate; but the impact is clear-you are feeling something for them. Among the characters the two performances which stand out are: Burt Reynolds as Director Jack Horner, and Mark Wahlberg as Eddie Adams/Dirk Diggler. Julianne Moore is also brillant, as is Heather Graham...but if I focus on any one actor it would have to be John C. Reilly. John\\'s performance is a perfect balance of comedic timing and character driven emotion...I\\'m a sucker for the line \"Ever see the movie Star Wars?...People say I look like Han Solo.\" Anyway, the look of the film is incredible, the Director of Photography and Director/Writer/Producer, have come up with a vibrant colour, and flashy style that compares to Martin Scorsese, and Stanley Kubrick(in terms of his perfection of his craft); but with creating his own unique look, and pushing the edge with the longest single shot I\\'ver ever seen...that being the New Year\\'s party sequence.<br /><br />The music, like in any great film, is a character of its own. At times, it consumes oneself with sorrow or grief...but mainly its all about fun, dancing, and having a good time; the spirit of the 1970\\'s. OK, back to the performances.<br /><br />Burt Reynolds plays the character of Jack Horner, a porn director who feels the burden of what the future of \"film\" means to his genre. The awful transition from shooting on film to recording on magnetic tape. The lose of his art, as it were...and the changes in mentality to the people he works with. Walhberg adds the perfect blend of innocense and sexual bravado needed for the character. For all those individuals who have seen Burton\\'s Planet of the Apes, pay no attention to the performance of Wahlberg in that film...rent boogie nights and see what a difference a good script can make!<br /><br />Julianne Moore plays the would-be mother to all, and with that comes the torment and anguish she feels, as life imitates art; and she loses all those close to her. Heather Graham is the eye-candy, but later holds her own, and steals some of the scenes from even the great Mr. Reynolds himself. Each character is multidimensional, rich with life, and performed by actors that seem to be picture perfect for the part.<br /><br />The film itself is often funny, tragic, exciting, and provides a uncompromising look into the turblulant lifestyle of the fast-pace 1970\\'s. It makes no excuses, and tells no lies; and offers the audience a trip back. But even more importantly, the movie gives us a grand example of how films should be made; and a new director whose bold visions bring back art in film.']\n"
     ]
    }
   ],
   "source": [
    "print('x:')\n",
    "print(x_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print('y:')\n",
    "print(y_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbTokenizer = Tokenizer(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbTokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 the\n",
      "11 this\n",
      "5 to\n",
      "6 is\n",
      "7 br\n",
      "15 for\n",
      "19 film\n",
      "10 i\n",
      "14 as\n",
      "9 it\n",
      "4 of\n",
      "8 in\n",
      "16 with\n",
      "12 that\n",
      "13 was\n",
      "18 but\n",
      "3 a\n",
      "2 and\n",
      "17 movie\n"
     ]
    }
   ],
   "source": [
    "# print top 20 words\n",
    "for word, value in imdbTokenizer.word_index.items():\n",
    "    if value < 20:\n",
    "        print(value, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create int to word dictionary\n",
    "intToWord = {}\n",
    "for word, value in imdbTokenizer.word_index.items():\n",
    "    intToWord[value] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "and\n",
      "an\n"
     ]
    }
   ],
   "source": [
    "# add a symbol for null placeholder\n",
    "intToWord[0] = \"!!!NA!!!\"\n",
    "\n",
    "print(intToWord[1])\n",
    "print(intToWord[2])\n",
    "print(intToWord[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie makes me want to fall in love all over again!I am naming my next daughter \"Adelaide\". Just so that someone who sings like Ol Blue eyes can swoon her one day, and feel the butterflies I felt hearing it sung, and it wasn't even to me! I give it a 9/10\n",
      "[[11, 17, 163, 69, 178, 5, 806, 8, 116, 29, 117, 171, 10, 241, 10923, 58, 372, 575, 11696, 40, 35, 12, 291, 34, 3130, 37, 1332, 520, 67, 38, 28, 248, 2, 231, 1, 16550, 10, 417, 2229, 9, 5311, 2, 9, 283, 57, 5, 69, 10, 199, 9, 3, 786, 155]]\n",
      "this\n",
      "movie\n",
      "makes\n",
      "me\n",
      "want\n",
      "to\n",
      "fall\n",
      "in\n",
      "love\n",
      "all\n",
      "over\n",
      "again\n",
      "i\n",
      "am\n",
      "naming\n",
      "my\n",
      "next\n",
      "daughter\n",
      "adelaide\n",
      "just\n",
      "so\n",
      "that\n",
      "someone\n",
      "who\n",
      "sings\n",
      "like\n",
      "blue\n",
      "eyes\n",
      "can\n",
      "her\n",
      "one\n",
      "day\n",
      "and\n",
      "feel\n",
      "the\n",
      "butterflies\n",
      "i\n",
      "felt\n",
      "hearing\n",
      "it\n",
      "sung\n",
      "and\n",
      "it\n",
      "wasn't\n",
      "even\n",
      "to\n",
      "me\n",
      "i\n",
      "give\n",
      "it\n",
      "a\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# convert word strings to integer sequence lists\n",
    "print(x_train[0])\n",
    "print(imdbTokenizer.texts_to_sequences(x_train[:1]))\n",
    "for value in imdbTokenizer.texts_to_sequences(x_train[:1])[0]:\n",
    "    print(intToWord[value],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = imdbTokenizer.texts_to_sequences(x_train)\n",
    "x_test = imdbTokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (25000, 200)\n",
      "x_test shape:  (25000, 200)\n"
     ]
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('x_test shape: ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model hyper parameters\n",
    "epochs = 15\n",
    "embedding_neurons = 128\n",
    "lstm_neurons = 64\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(maxlen, ), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(max_features, embedding_neurons, input_length=maxlen)(input_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnorm = BatchNormalization()(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwards = LSTM(lstm_neurons, dropout=0.2, recurrent_dropout=0.2)(bnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_dp = Dropout(0.5)(forwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Dense(1, activation='sigmoid')(after_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=sequence1, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200, 128)          512       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,609,985.0\n",
      "Trainable params: 2,609,729.0\n",
      "Non-trainable params: 256.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='./lstm_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "190s - loss: 0.4840 - acc: 0.7655 - val_loss: 0.4242 - val_acc: 0.8214\n",
      "Epoch 2/15\n",
      "189s - loss: 0.2563 - acc: 0.9016 - val_loss: 0.3245 - val_acc: 0.8734\n",
      "Epoch 3/15\n",
      "189s - loss: 0.1538 - acc: 0.9451 - val_loss: 0.3668 - val_acc: 0.8622\n",
      "Epoch 4/15\n",
      "187s - loss: 0.0908 - acc: 0.9688 - val_loss: 0.4262 - val_acc: 0.8606\n",
      "Epoch 5/15\n",
      "188s - loss: 0.0590 - acc: 0.9794 - val_loss: 0.5070 - val_acc: 0.8607\n",
      "Epoch 6/15\n",
      "187s - loss: 0.0439 - acc: 0.9854 - val_loss: 0.5800 - val_acc: 0.8590\n",
      "Epoch 7/15\n",
      "186s - loss: 0.0314 - acc: 0.9898 - val_loss: 0.6515 - val_acc: 0.8478\n",
      "Epoch 8/15\n",
      "189s - loss: 0.0316 - acc: 0.9898 - val_loss: 0.6443 - val_acc: 0.8587\n",
      "Epoch 9/15\n",
      "188s - loss: 0.0229 - acc: 0.9928 - val_loss: 0.7170 - val_acc: 0.8608\n",
      "Epoch 10/15\n",
      "184s - loss: 0.0169 - acc: 0.9944 - val_loss: 0.7275 - val_acc: 0.8567\n",
      "Epoch 11/15\n",
      "189s - loss: 0.0147 - acc: 0.9956 - val_loss: 0.8177 - val_acc: 0.8472\n",
      "Epoch 12/15\n",
      "187s - loss: 0.0134 - acc: 0.9962 - val_loss: 0.8746 - val_acc: 0.8509\n",
      "Epoch 13/15\n",
      "189s - loss: 0.0114 - acc: 0.9966 - val_loss: 0.9094 - val_acc: 0.8558\n",
      "Epoch 14/15\n",
      "189s - loss: 0.0098 - acc: 0.9972 - val_loss: 0.8442 - val_acc: 0.8532\n",
      "Epoch 15/15\n",
      "189s - loss: 0.0136 - acc: 0.9958 - val_loss: 0.8592 - val_acc: 0.8550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.keras.python.keras.callbacks.History at 0x7f19559810b8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), callbacks=[tensorboard], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.859218871113\n",
      "Test accuracy: 0.85496\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open('model_json.json', 'w') as file:\n",
    "    json.dump(model_json, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_weight.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
